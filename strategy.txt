# Finch Strategy: The "Shadow AI" Pivot (2026)

## 1. Контекст и Проблема
Наша текущая гипотеза (обертка над OpenAI/Anthropic) ведет в "Алый океан". Интерфейсы копируются, конкуренция растет, гиганты (Oracle, Microsoft) давят экспертизой.
Мы меняем подход. Мы не конкурируем в гонке "У кого больше облачная модель". Мы меняем поле игры.

### Инсайт 2026 года: Железо победило
Идея "Эппл проиграл ИИ гонку" ошибочна. Эппл выиграл гонку **локального инференса**.
В 2026 году "ноутбук 5-летней давности" — это MacBook Air M1. Это база.
Это значит, что на компьютере любого целевого пользователя (консультанта, офицера, аудитора) можно локально запустить квантованную модель уровня 20B (или очень быструю 7B-8B), которая по качеству превосходит GPT-4 образца 2024 года.

## 2. Стратегия "Safe Shadow AI" (Троянский конь)
Мы **НЕ** идем продавать энтерпрайз-лицензию банку в первый день. Это долгие циклы продаж (18 месяцев) и бюрократия.

### Реальность рынка:
*   **78% сотрудников** уже используют GenAI (ChatGPT, Claude) в работе, нарушая прямые запреты служб безопасности.
*   Они делают это, потому что это нужно им для выживания и эффективности.
*   Риск: Данные уходят в облако.

### Наше решение:
Мы легализуем "теневое использование". Мы даем сотруднику инструмент, который:
1.  **Умнее:** Дообучен (Fine-tuned) специально на комплаенс-задачи (лучше generic моделей).
2.  **Безопаснее:** Работает 100% локально (On-Premise на устройстве). Интернет-кабель можно выдернуть.
*   **Аргумент для сотрудника:** "Используй Finch вместо ChatGPT. Ты получишь лучший результат, и тебя не уволят за утечку данных, потому что утечки технически невозможны".

### Почему победит качество модели, а не маркетинг?
На рынке AI побеждает **лучшая модель**, а не бюджет на рекламу. 
Яркий пример: даже сотрудники Microsoft в работе часто используют Claude (Anthropic), а не родной Microsoft Copilot. Почему? Потому что для сложной интеллектуальной работы (кодинг, анализ) люди выбирают инструмент, который *умнее*, даже если корпоративная политика навязывает свой "безопасный" продукт.
Мы ставим на то, что сотрудники банков выберут Finch, потому что он будет лучше решать их специфические задачи, чем general-модели.

## 3. Техническое решение: Small Language Models (SLM) + Federated Learning
Вместо аренды дорогих GPU (Bedrock/Azure), мы используем вычислительную мощность пользователей.

*   **Локальный инференс:** Модель работает на чипах Apple Silicon / NVIDIA RTX пользователей. OpEx = 0.
*   **Федеративное обучение:** Чтобы модель умнела, мы используем Federated Learning. Локальные машины дообучаются на кейсах пользователя и отправляют в центр **только веса (математические градиенты)**, а не сами данные.
*   **Приватность:** Мы строим самую умную модель в мире, не видя ни одного секретного документа.

## 4. Дистрибуция и Экономика
*   **Модель:** Free / Freemium.
*   **Сделка с пользователем:** Мы даем тебе лучший ИИ-инструмент бесплатно. Взамен твой компьютер участвует в федеративном обучении (анонимно улучшает общую модель).
*   **Целевая аудитория (Phase 1):** Независимые консультанты, бутик-фирмы, сотрудники финтехов (BYOD), крипто-стартапы. Люди, которые сами контролируют свои ноутбуки.
*   **Инвестиции:** Тратим деньги только на R&D (команду), а не на сервера.

## 5. Долгосрочная цель (The Endgame)
Через 2 года, когда Finch будет стоять на тысячах ноутбуков сотрудников "в серую":
1.  Мы получим модель, обученную на реальных "боевых" данных, которых нет у OpenAI.
2.  Мы придем к CISO (директору по безопасности) и скажем: "Ваши сотрудники уже используют Finch. Это стандарт де-факто. Давайте купим Enterprise-лицензию, чтобы вы могли централизованно управлять политиками и мониторить риски".
3.  Мы продаем InfoSec-инструменты поверх нашей бесплатной сети.

**Итог:** Мы строим "Signal для AI". Приватный, локальный, незаблокируемый.